{"train/stage0_loss_cls": 2.3538896322250364, "train/stage0_pos_acc": 0.0, "train/stage0_loss_bbox": 1.9020288825035094, "train/stage0_loss_iou": 1.0334935879707337, "train/stage1_loss_cls": 2.3575398826599123, "train/stage1_pos_acc": 0.0, "train/stage1_loss_bbox": 2.0691247248649596, "train/stage1_loss_iou": 1.1993314933776855, "train/stage2_loss_cls": 2.4273141503334044, "train/stage2_pos_acc": 4.0, "train/stage2_loss_bbox": 2.203260463476181, "train/stage2_loss_iou": 1.2905854761600495, "train/stage3_loss_cls": 2.47179151058197, "train/stage3_pos_acc": 0.6666666412353516, "train/stage3_loss_bbox": 2.8079641127586363, "train/stage3_loss_iou": 1.5276237511634827, "train/stage4_loss_cls": 2.404876239299774, "train/stage4_pos_acc": 0.0, "train/stage4_loss_bbox": 2.8506219124794008, "train/stage4_loss_iou": 1.542307243347168, "train/stage5_loss_cls": 2.3957114219665527, "train/stage5_pos_acc": 0.0, "train/stage5_loss_bbox": 3.1256922459602356, "train/stage5_loss_iou": 1.753523690700531, "train/loss": 37.71668041229248, "train/grad_norm": 28082.189775390623, "learning_rate": 4.970049999999998e-06, "momentum": 0.9, "_timestamp": 1649946605, "_runtime": 36, "_step": 100, "_wandb": {"runtime": 47}}