{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /opt/ml/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2022-6-2 Python-3.8.13 torch-1.11.0+cu102 CUDA:0 (Tesla V100-PCIE-32GB, 32510MiB)\n",
      "\n",
      "YOLOv5 üöÄ 2022-6-2 Python-3.8.13 torch-1.11.0+cu102 CUDA:0 (Tesla V100-PCIE-32GB, 32510MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Adding AutoShape... \n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "Model summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n",
      "Model summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import modules.model as model\n",
    "import modules.changeDetector as changeDetector\n",
    "\n",
    "model_flow = model.stockChecker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(img,bbox):\n",
    "    lw = 10\n",
    "    for (x,y,w,h),label,state in bbox:\n",
    "        if state == \"add\":\n",
    "            if state == \"zero\":\n",
    "                img = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), lw) #Îπ®Í∞ï\n",
    "            if state == 'new': \n",
    "                img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), lw) #ÌååÎûë\n",
    "            if state == 'sub':\n",
    "                img = cv2.rectangle(img, (x, y), (x+w, y+h), (147, 20, 255), lw) # ÏûêÏ£º\n",
    "            if state == 'add':\n",
    "                img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 191, 0), lw) # ÌïòÎäò\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"/opt/ml/project/final-project-level3-cv-12/modules/Test4.mp4\")\n",
    "bbox = []\n",
    "ramen = {}\n",
    "first = True\n",
    "human = False\n",
    "cnt = 0\n",
    "flag = False\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(\"./output_test_trim.mp4\",fourcc,30,(1440,1440))\n",
    "for cnt in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    if cnt % 5 != 0:\n",
    "        ret ,image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if bbox:\n",
    "            image = annotate(image,bbox)\n",
    "        out.write(image)\n",
    "        continue\n",
    "    ret , image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    if first:\n",
    "        output = model_flow.ramen_detect(image)\n",
    "        for i in output:\n",
    "            check_label = model_flow.ramen_class(image,[i])\n",
    "            if check_label[0] in ramen.keys():\n",
    "                ramen[check_label[0]][\"base\"] += 1\n",
    "            else:\n",
    "                ramen[check_label[0]] = {\"base\" : 1 , \"diff\" : 0}\n",
    "        check_image = image.copy()\n",
    "        first = False\n",
    "        ramen = pd.DataFrame(ramen).transpose()\n",
    "        ramen.to_csv('/opt/ml/project/final-project-level3-cv-12/front/stock.csv')\n",
    "        \n",
    "    if not human:\n",
    "        human = model_flow.check_human(image)  # \n",
    "    if human and not model_flow.check_human(image):\n",
    "        _, next_image = cap.read()\n",
    "        if changeDetector.get_diff(image,next_image).mean() < 0.95:\n",
    "            flag = True\n",
    "        else:\n",
    "            bbox= model_flow.check(check_image,image,is_topDown=True)\n",
    "            check_image = image.copy()\n",
    "            if bbox:\n",
    "                for (x,y,w,h) , label,state in bbox:\n",
    "                    if label not in ramen.keys():\n",
    "                        continue\n",
    "                    if state in ['sub','zero']:\n",
    "                        ramen.loc[label,'diff'] -= 1\n",
    "                    else:\n",
    "                        ramen.loc[label,'diff'] += 1\n",
    "                image = annotate(image,bbox)\n",
    "                ramen.to_csv('/opt/ml/project/final-project-level3-cv-12/front/stock.csv')\n",
    "            human = False\n",
    "            \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    out.write(image)\n",
    "    if flag:\n",
    "        out.write(next_image)\n",
    "        flag = False\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python ('fastapi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
